# SACFormer
Soft Actor-Critic (SAC) with Transformers in Gymnasium & MuJoCo

ğŸ“Œ Overview

This project implements a modern Soft Actor-Critic (SAC) reinforcement learning agent powered by Transformers instead of traditional MLPs, running on MuJoCo environments (Gymnasium). It is optimized for multi-GPU training, efficient experience replay, and parallelized execution.

ğŸš€ Features

âœ… SAC-Based RL â€“ Uses Soft Actor-Critic for optimal policy learning.âœ… Transformer-Based Actor â€“ Replaces MLP with self-attention for better sequential decision-making.âœ… MuJoCo + Gymnasium â€“ High-quality physics simulations for better training.âœ… Multi-GPU Training â€“ Supports distributed learning with Ray RLlib.âœ… Vectorized Environments â€“ Stable-Baselines3 VecEnv for faster rollouts.âœ… Prioritized Experience Replay (PER) â€“ Smart sampling for efficient learning.âœ… TensorBoard & WandB Integration â€“ Real-time monitoring & hyperparameter tuning.

ğŸ“‚ Directory Structure
```plaintext
SAC-Transformer-RL/
â”‚â”€â”€ agents/                     # SAC Agent & Models
â”‚   â”œâ”€â”€ policy.py                # Transformer-based Actor-Critic
â”‚   â”œâ”€â”€ sac_agent.py             # SAC Trainer
â”‚   â”œâ”€â”€ q_network.py             # Twin Q-Networks
â”‚   â”œâ”€â”€ replay_buffer.py         # PER Experience Replay
â”‚   â”œâ”€â”€ train.py                 # Training Script
â”‚   â”œâ”€â”€ evaluation.py            # Evaluation Script
â”‚
â”‚â”€â”€ environments/                # Environment Setup
â”‚   â”œâ”€â”€ gym_env.py               # Gymnasium Wrapper
â”‚   â”œâ”€â”€ vec_env.py               # Parallelized VecEnv
â”‚   â”œâ”€â”€ mujoco_envs.py           # MuJoCo Integration
â”‚
â”‚â”€â”€ utils/                       # Helper Functions
â”‚   â”œâ”€â”€ logging.py               # TensorBoard & WandB Integration
â”‚   â”œâ”€â”€ config.py                # Hyperparameter Storage
â”‚   â”œâ”€â”€ utils.py                 # Common Utilities
â”‚
â”‚â”€â”€ training_scripts/            # Different Training Variants
â”‚   â”œâ”€â”€ sac_train.py             # Standard SAC Training
â”‚   â”œâ”€â”€ sac_ray_train.py         # Multi-GPU Training with Ray
â”‚   â”œâ”€â”€ sac_hyperparam_search.py # Auto Hyperparameter Tuning
â”‚
â”‚â”€â”€ logs/                        # Training Logs
â”‚
â”‚â”€â”€ models/                      # Saved Models
â”‚   â”œâ”€â”€ sac_halfcheetah.pth      # SAC Weights
â”‚
â”‚â”€â”€ README.md                    # Documentation
â”‚â”€â”€ requirements.txt              # Dependencies
â”‚â”€â”€ train.py                      # Main Entry Point
```
ğŸ’¾ Installation

pip install torch stable-baselines3[extra] gymnasium mujoco ray rllib numpy wandb

ğŸ› ï¸ Usage

Train SAC with Transformers on HalfCheetah-v4:

python training_scripts/sac_train.py

Run parallel training with Ray RLlib:

python training_scripts/sac_ray_train.py

Perform automated hyperparameter tuning:

python training_scripts/sac_hyperparam_search.py

ğŸ”¬ Improvements Over Old Repo

Old ARS Project

New SAC-Transformer Project

Augmented Random Search (ARS)

âœ… Soft Actor-Critic (SAC)

PyBullet Environments

âœ… MuJoCo + Gymnasium

No GPU Support

âœ… Multi-GPU (Ray RLlib)

Manual Policy Updates (NumPy)

âœ… Transformer-Based Actor-Critic

No Parallelization

âœ… Vectorized Environments (VecEnv)

Basic Replay Buffer

âœ… Prioritized Experience Replay (PER)

Minimal Logging

âœ… TensorBoard + WandB

ğŸ”® Future Plans

ğŸ”¹ Add Meta-RL support (Memory-Augmented Networks).ğŸ”¹ Experiment with GATO / Decision Transformer.ğŸ”¹ Optimize JAX version for TPU acceleration.

ğŸ’¡ Why This is the Best Modern RL Setup

âœ… State-of-the-Art RL (SAC + Transformers)âœ… High-Quality Physics (MuJoCo)âœ… Parallel Training (Ray RLlib)âœ… Production-Ready Code

ğŸ”¥ This framework is built for RL research and deployment. ğŸš€

